#GOV UK FM Strategy

library(rvest)
library(tm)
library(wordcloud)
library(topicmodels)
library(textdata)
library(rvest)
library(tidyverse) 
library(tidytext)
library(dplyr)
library(tidyr)   
library(reshape2)
library(forcats)
library(scales)
library(stringr)
library(ggplot2)
library(igraph)
library(ggraph)
library(antiword)
library(syuzhet)
library(RColorBrewer)
library(wordcloud2)

# Read HTML content from the website
artigo_UK <- read_html("https://www.gov.uk/government/publications/facilities-management-strategy/facilities-management-strategy-html")

# Extract text from HTML
text_content <- html_text(artigo_UK)

# Tokenize the text into words
words_before_cleaning <- unlist(strsplit(text_content, "\\s+"))

# Define the words to include in stopwords
words_to_include_in_stopwords <- c("will", "uctruen", "across", "ensure")

# Add the specific words to the stopwords list
custom_stopwords <- c(stopwords("en"), words_to_include_in_stopwords)

# Create a Corpus for text processing
corpus <- Corpus(VectorSource(text_content))

# Perform text cleaning with the custom stopwords list
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, custom_stopwords)
corpus <- tm_map(corpus, stripWhitespace)

# Create a Document-Term Matrix
dtm <- DocumentTermMatrix(corpus)

# Get word frequencies
word_freq <- colSums(as.matrix(dtm))

# Create a data frame with words and their frequencies
word_freq_df <- data.frame(word = names(word_freq), freq = word_freq)

# Order the data frame by frequency in descending order
word_freq_df <- word_freq_df[order(-word_freq_df$freq), ]

# Display the top words
head(word_freq_df, 16)

# Count the number of words
total_words <- sum(word_freq)

cat("Total number of words:", total_words, "\n")

# Create a word cloud
wordcloud(words = word_freq_df$word, freq = word_freq_df$freq, scale=c(3,0.5), min.freq = 2, colors = brewer.pal(8, "Dark2"))
wordcloud(words = word_freq_df$word, freq = word_freq_df$word = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
wordcloud(words = word_freq_df$word, freq = word_freq_df$freq, min.freq = 1,max.words=300, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))

###############sentiments analysis####################

texto <- scan (file = "https://www.gov.uk/government/publications/facilities-management-strategy/facilities-management-strategy-html", fileEncoding = "UTF-8", what = character(), sep = "\n", allowEscapes = T)
texto_palavras <- get_tokens(texto)
head(texto_palavras)
class (texto_palavras)
length(texto_palavras)
oracoes_vetor <- get_sentences(texto)
length(oracoes_vetor)

sentimentos_df <- get_nrc_sentiment(texto_palavras, lang="english")

head(sentimentos_df)

summary(sentimentos_df)


barplot(colSums(prop.table(sentimentos_df[, 1:8])))

sentimentos_valencia <- (sentimentos_df$negative * -1) + sentimentos_df$positive

simple_plot(sentimentos_valencia)

#END
